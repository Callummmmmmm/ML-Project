{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3e1455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_imports import *\n",
    "from data_clean import data\n",
    "clean_df = data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b4e65eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL:\n",
    "    def __init__(self, input_data, target_var, model):\n",
    "        \"\"\"\n",
    "        Initialize the Model with input data and target variable.\n",
    "\n",
    "        :param input_data: DataFrame containing the input data.\n",
    "        :param target_var: Name of the target variable column.\n",
    "        \"\"\"\n",
    "        self.input_data = input_data\n",
    "        self.target_var = target_var\n",
    "        self.model = model\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.train_test_metrics = None\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Prepare data by separating features and target variable,\n",
    "        and splitting into training and testing sets.\n",
    "        \"\"\"\n",
    "        df_not_missing = self.input_data.dropna(subset=[self.target_var])\n",
    "        X = df_not_missing.drop(columns=[self.target_var])\n",
    "        y = df_not_missing[self.target_var]\n",
    "        \n",
    "        # Split the data into train and test subsets.\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=1\n",
    "        )\n",
    "    \n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "        Train the HistGradientBoostingRegressor model.\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise ValueError(\"Data has not been prepared. Call prepare_data() first.\")\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "    \n",
    "    def predict(self, new_data):\n",
    "        \"\"\"\n",
    "        Predict target values for new data using the trained model.\n",
    "\n",
    "        :param new_data: DataFrame containing the new input data.\n",
    "        :return: Array of predicted values.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained. Call train_model() first.\")\n",
    "        return self.model.predict(new_data)\n",
    "    \n",
    "    def fill_missing_values(self):\n",
    "        \"\"\"\n",
    "        Predict and fill missing values in the original input data.\n",
    "        \n",
    "        :return: DataFrame with missing values filled.\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise ValueError(\"Data has not been prepared. Call prepare_data() first.\")\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained. Call train_model() first.\")\n",
    "        \n",
    "        df_missing = self.input_data[self.input_data[self.target_var].isnull()]\n",
    "        if not df_missing.empty:\n",
    "            X_missing = df_missing.drop(columns=[self.target_var])\n",
    "            self.input_data.loc[self.input_data[self.target_var].isnull(), self.target_var] = self.model.predict(X_missing)\n",
    "        \n",
    "        return self.input_data\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Evaluate the model using regression metrics for both training and testing sets.\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise ValueError(\"Data has not been prepared. Call prepare_data() first.\")\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained. Call train_model() first.\")\n",
    "        \n",
    "        # Predictions on the training and test set.\n",
    "        y_train_pred = self.model.predict(self.X_train)\n",
    "        y_test_pred = self.model.predict(self.X_test)\n",
    "\n",
    "        # Calculating regression metrics for the training set.\n",
    "        mse_train = mean_squared_error(self.y_train, y_train_pred)\n",
    "        rmse_train = mse_train ** 0.5\n",
    "        mae_train = mean_absolute_error(self.y_train, y_train_pred)\n",
    "        r2_train = r2_score(self.y_train, y_train_pred)\n",
    "\n",
    "        # Calculating regression metrics for the test set.\n",
    "        mse_test = mean_squared_error(self.y_test, y_test_pred)\n",
    "        rmse_test = mse_test ** 0.5\n",
    "        mae_test = mean_absolute_error(self.y_test, y_test_pred)\n",
    "        r2_test = r2_score(self.y_test, y_test_pred)\n",
    "        \n",
    "        self.train_test_metrics = {\n",
    "            'train': {'mse': mse_train, 'rmse': rmse_train, 'mae': mae_train, 'r2': r2_train},\n",
    "            'test': {'mse': mse_test, 'rmse': rmse_test, 'mae': mae_test, 'r2': r2_test}\n",
    "        }\n",
    "\n",
    "        # Print training and testing set regression metrics.\n",
    "        print(f'Training Set - MSE: {mse_train:8.5f}, RMSE: {rmse_train:8.5f}, MAE: {mae_train:8.5f}, R2: {r2_train:8.5f}')\n",
    "        print(f'Testing Set  - MSE: {mse_test:8.5f}, RMSE: {rmse_test:8.5f}, MAE: {mae_test:8.5f}, R2: {r2_test:8.5f}')\n",
    "    \n",
    "    def model_metrics(self):\n",
    "        \"\"\"\n",
    "        Model evaluation metrics, used for plots.\n",
    "        \n",
    "        :return: Dictionary of training and testing metrics.\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise ValueError(\"Data has not been prepared. Call prepare_data() first.\")\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained. Call train_model() first.\")\n",
    "\n",
    "        return self.train_test_metrics\n",
    "    \n",
    "    def shap_summary(self, file_name, title):\n",
    "        \"\"\"\n",
    "        Summarise the top SHAP features for the model.\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise ValueError(\"Data has not been prepared. Call prepare_data() first.\")\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained. Call train_model() first.\")\n",
    "            \n",
    "        # SHAP analysis\n",
    "        explainer = shap.Explainer(self.model)\n",
    "        self.shap_values = explainer.shap_values(self.X_test)\n",
    "        shap.summary_plot(self.shap_values, self.X_test, show = False)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.savefig(f'/Users/callumwilson/Documents/GitHub/ML-Project/Output/{file_name}.png', bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def shap_top_features(self, top_n):\n",
    "        \"\"\"\n",
    "        Calculate and return the top N features based on SHAP values.\n",
    "\n",
    "        :param top_n: Number of top features to return.\n",
    "        :return: DataFrame with the top N features and the target variable.\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise ValueError(\"Data has not been prepared. Call prepare_data() first.\")\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained. Call train_model() first.\")\n",
    "\n",
    "        # Calculate mean absolute SHAP values for each feature\n",
    "        shap_importance = np.abs(self.shap_values).mean(axis=0)\n",
    "        top_n_indices = np.argsort(shap_importance)[-top_n:][::-1]  # Indices of the top N features\n",
    "        top_n_features = self.X_test.columns[top_n_indices]\n",
    "        \n",
    "        # Return DataFrame with top N features and target variable\n",
    "        return self.input_data[top_n_features.to_list() + [self.target_var]]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f3b0a57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Model\n",
      "Training Model\n",
      "Evaluating Model\n",
      "Training Set - MSE: 11.54945, RMSE:  3.39845, MAE:  2.59046, R2:  0.78803\n",
      "Testing Set  - MSE: 12.02467, RMSE:  3.46766, MAE:  2.65498, R2:  0.77958\n",
      "Model Metrics\n",
      "Model SHAP Summary\n",
      "Top SHAP Features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEMP_7.5M_degC</th>\n",
       "      <th>RH_10M_%</th>\n",
       "      <th>CO_ppbV</th>\n",
       "      <th>ethane_pptV</th>\n",
       "      <th>WIND_SPEED_7.5M_m/s</th>\n",
       "      <th>O3_ppbV</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date and Time (UTC)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-10-02 16:00:00</th>\n",
       "      <td>33.8</td>\n",
       "      <td>70.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499.48</td>\n",
       "      <td>4.6</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-02 17:00:00</th>\n",
       "      <td>34.5</td>\n",
       "      <td>70.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-02 18:00:00</th>\n",
       "      <td>36.5</td>\n",
       "      <td>70.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>499.48</td>\n",
       "      <td>5.1</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-02 19:00:00</th>\n",
       "      <td>36.8</td>\n",
       "      <td>70.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>476.07</td>\n",
       "      <td>5.3</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-10-02 20:00:00</th>\n",
       "      <td>37.4</td>\n",
       "      <td>70.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>496.36</td>\n",
       "      <td>5.3</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 19:00:00</th>\n",
       "      <td>23.9</td>\n",
       "      <td>83.2</td>\n",
       "      <td>98.518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 20:00:00</th>\n",
       "      <td>24.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>98.874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 21:00:00</th>\n",
       "      <td>24.0</td>\n",
       "      <td>79.5</td>\n",
       "      <td>99.368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 22:00:00</th>\n",
       "      <td>23.9</td>\n",
       "      <td>80.1</td>\n",
       "      <td>99.337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:00:00</th>\n",
       "      <td>23.8</td>\n",
       "      <td>80.9</td>\n",
       "      <td>99.990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151184 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TEMP_7.5M_degC  RH_10M_%  CO_ppbV  ethane_pptV  \\\n",
       "Date and Time (UTC)                                                   \n",
       "2006-10-02 16:00:00            33.8      70.7      NaN       499.48   \n",
       "2006-10-02 17:00:00            34.5      70.8      NaN          NaN   \n",
       "2006-10-02 18:00:00            36.5      70.4      NaN       499.48   \n",
       "2006-10-02 19:00:00            36.8      70.2      NaN       476.07   \n",
       "2006-10-02 20:00:00            37.4      70.3      NaN       496.36   \n",
       "...                             ...       ...      ...          ...   \n",
       "2023-12-31 19:00:00            23.9      83.2   98.518          NaN   \n",
       "2023-12-31 20:00:00            24.0      80.0   98.874          NaN   \n",
       "2023-12-31 21:00:00            24.0      79.5   99.368          NaN   \n",
       "2023-12-31 22:00:00            23.9      80.1   99.337          NaN   \n",
       "2023-12-31 23:00:00            23.8      80.9   99.990          NaN   \n",
       "\n",
       "                     WIND_SPEED_7.5M_m/s  O3_ppbV  \n",
       "Date and Time (UTC)                                \n",
       "2006-10-02 16:00:00                  4.6     17.3  \n",
       "2006-10-02 17:00:00                  4.9     17.9  \n",
       "2006-10-02 18:00:00                  5.1     18.5  \n",
       "2006-10-02 19:00:00                  5.3     19.0  \n",
       "2006-10-02 20:00:00                  5.3     21.2  \n",
       "...                                  ...      ...  \n",
       "2023-12-31 19:00:00                  4.0      NaN  \n",
       "2023-12-31 20:00:00                  4.3      NaN  \n",
       "2023-12-31 21:00:00                  4.0      NaN  \n",
       "2023-12-31 22:00:00                  4.0      NaN  \n",
       "2023-12-31 23:00:00                  4.1      NaN  \n",
       "\n",
       "[151184 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = HistGradientBoostingRegressor(random_state=1)\n",
    "M = MODEL(clean_df, 'O3_ppbV', mod)\n",
    "\n",
    "print('Preparing Model')\n",
    "M.prepare_data()\n",
    "\n",
    "print('Training Model')\n",
    "M.train_model()\n",
    "\n",
    "print('Evaluating Model')\n",
    "M.evaluate_model()\n",
    "\n",
    "print('Model Metrics')\n",
    "M.model_metrics()\n",
    "\n",
    "print('Model SHAP Summary')\n",
    "M.shap_summary(file_name = 'SSHAP', title = 'SHAP')\n",
    "\n",
    "print('Top SHAP Features')\n",
    "M.shap_top_features(top_n=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c79572f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ATM_PRESSURE_7.5M_hPa\n- CH4_REVISED_ppbV\n- CH4_WITH_MPI_FLASKS_ppbV\n- CO2_REVISED_ppmV\n- CO2_WITH_MPI_FLASKS_ppmV\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 179\u001b[0m, in \u001b[0;36mMODEL.evaluate_importance\u001b[0;34m(self, max_features)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Train and evaluate the model using the selected features\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m--> 179\u001b[0m metrics_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# Append metrics for both training and testing sets\u001b[39;00m\n\u001b[1;32m    182\u001b[0m MSE[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(metrics_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[23], line 79\u001b[0m, in \u001b[0;36mMODEL.evaluate_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel has not been trained. Call train_model() first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Predictions on the training and test set.\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Calculating regression metrics for the training set.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1487\u001b[0m, in \u001b[0;36mHistGradientBoostingRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1484\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;66;03m# Return inverse link of raw predictions after converting\u001b[39;00m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;66;03m# shape (n_samples, 1) to (n_samples,)\u001b[39;00m\n\u001b[0;32m-> 1487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mlink\u001b[38;5;241m.\u001b[39minverse(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1022\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._raw_predict\u001b[0;34m(self, X, n_threads)\u001b[0m\n\u001b[1;32m   1020\u001b[0m is_binned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_in_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_binned:\n\u001b[0;32m-> 1022\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_DTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:529\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    466\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    471\u001b[0m ):\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    533\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:462\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    458\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m     )\n\u001b[0;32m--> 462\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ATM_PRESSURE_7.5M_hPa\n- CH4_REVISED_ppbV\n- CH4_WITH_MPI_FLASKS_ppbV\n- CO2_REVISED_ppmV\n- CO2_WITH_MPI_FLASKS_ppmV\n- ...\n"
     ]
    }
   ],
   "source": [
    "M.evaluate_importance(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "427f39b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set - MSE: 12.64969, RMSE:  3.55664, MAE:  2.70937, R2:  0.76784\n",
      "Testing Set  - MSE: 13.07726, RMSE:  3.61625, MAE:  2.77551, R2:  0.76028\n"
     ]
    }
   ],
   "source": [
    "L = M.shap_top_features(15)\n",
    "C = MODEL(L, 'O3_ppbV', mod)\n",
    "C.prepare_data()\n",
    "C.train_model()\n",
    "C.evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
